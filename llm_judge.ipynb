{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyNjscf8GILQ"
      },
      "source": [
        "# Using LLM-as-a-judge\n",
        "Asking GPT-3.5-turbo model to compare the two expert rewrite versions directly with the novice in terms of diversity and relevance, and ask model to return '1' v.s. '2'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "KmjNXxv6NxDi",
        "outputId": "6f2b5095-4f3f-4c0b-b89b-ea64f141f4f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64     A folk festival song with drums, bass, keyboar...\n",
              "78     A happy outdoor festival song with drums, bass...\n",
              "104    A song with a male singer and backup harmonies...\n",
              "160    Fun country dance music with drum beat, male v...\n",
              "171    Male singer with friends, piano, drums, bass, ...\n",
              "Name: novice, dtype: object"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Novice Version\n",
        "import pandas as pd\n",
        "df_novice = pd.read_csv(\"initial_dataset/step1_novice_gpt.csv\")\n",
        "hand_curated = [0, 5, 13, 15, 19, 30, 37, 41, 82, 91, 103, 114, 124, 139, 202, 436, 441, 455, 588, 614, 966, 971, 997, 1342]\n",
        "df_novice_minus_24 = df_novice.drop(index=hand_curated)\n",
        "\n",
        "df_novice_test = df_novice_minus_24[df_novice_minus_24['is_balanced_subset'] == True][\"novice\"]\n",
        "len(df_novice_test)\n",
        "df_novice_test.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "GnL6t5KiO4Lt",
        "outputId": "4e95ed18-e84f-41ae-96ff-840b5b51a3ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    This folk song features a percussionist playin...\n",
              "1    An acoustic drum is playing a four on the floo...\n",
              "2    A male singer sings this operatic melody with ...\n",
              "3    This music is a country dance piece. The tempo...\n",
              "4    A male singer sings this gospel song with back...\n",
              "dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import csv\n",
        "# Load Expert Verison 1\n",
        "with open('generation_result/gen_res_80_0.6.csv', newline = '') as f:\n",
        "    reader = csv.reader(f)\n",
        "    data = list(reader)\n",
        "    gen_res = []\n",
        "    for elem in data:\n",
        "      gen_res.append(str(elem[0]))\n",
        "\n",
        "len(gen_res)\n",
        "df_expert1_test = pd.Series(gen_res)\n",
        "df_expert1_test.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "I98okIbyPi_V",
        "outputId": "46bf7f09-031f-4ff9-faf3-aa1d21f7fed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64     Digital drums are playing a four on the floor ...\n",
              "78     An acoustic drum is playing along with a bassl...\n",
              "104    A male singer sings this beautiful melody with...\n",
              "160    A digital drum is playing a simple beat along ...\n",
              "171    The R&B music features a male voice singing an...\n",
              "Name: caption, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Expert Verison 2\n",
        "df_expert2 = pd.read_csv(\"paired_dataset/paired_dataset_LoRA.csv\") \n",
        "df_expert2_minus_24 = df_expert2.drop(index=hand_curated)\n",
        "\n",
        "df_expert2_test = df_expert2_minus_24[df_expert2_minus_24['is_balanced_subset'] == True][\"caption\"]\n",
        "len(df_expert2_test)\n",
        "df_expert2_test.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWoAIvnOZ1OH",
        "outputId": "a213187a-743f-489f-ffcc-b39602db9df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check row 500 match with other two datasets \n",
            " A catchy pop song from Finland with male vocals, clean guitar, bass, and keyboard, perfect for a teen drama or disco party.\n",
            "\n",
            " This is a pop music piece from Finland. There is a male vocal in the lead singing in a manner that is suitable for pop music. The clean guitar and the bass guitar are playing a simple tune. There is a keyboard playing in the melodic background. The rhythm is provided by an acoustic drum beat. The atmosphere is easygoing and generic. This piece could be used in the soundtrack of a teenage drama. It could also be playing in the background at a disco party. The music would also suit well with advertisement jingles.\n",
            "\n",
            " This is a Finnish pop piece. There is a male vocalist singing melodically in the Finnish language. In the background, a clean guitar and a groovy bass guitar can be heard playing the theme with the accompaniment of a keyboard. An 80s disco type beat is being played by the acoustic drums in the rhythmic background. There is a danceable aura to it. This piece could be used in the soundtrack of teenage dramas taking place in Finland. It could also be used in retro-themed disco party playlists.\n"
          ]
        }
      ],
      "source": [
        "print(\"Check row 500 match with other two datasets \\n\", df_novice_test.iloc[500])\n",
        "print(\"\\n\", df_expert1_test.iloc[500])\n",
        "print(\"\\n\", df_expert2_test.iloc[500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w4P3XO94lYUJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gRJEskQUqi3P"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "def evaluate_with_openai(novice_prompts, expert_version1, expert_version2):\n",
        "    scores = []\n",
        "    for novice, expert1, expert2 in zip(novice_prompts, expert_version1, expert_version2):\n",
        "        prompt = (\n",
        "            f\"Novice prompt: {novice}\\n\"\n",
        "            f\"Expert rewrite 1: {expert1}\\n\"\n",
        "            f\"Expert rewrite 2: {expert2}\\n\"\n",
        "            f\"Which rewrite is better in terms of diversity and relevance? Respond with either '1' or '2' only.\"\n",
        "        )\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert musician evaluating quality of prompts used for text-to-music generation.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ],\n",
        "                max_tokens=5,  # Limit response length\n",
        "                temperature=0.1,  # Encourage deterministic responses\n",
        "            )\n",
        "            # Extract and validate response\n",
        "            content = response.choices[0].message.content.strip()\n",
        "            print(f\"Response: {content}\")\n",
        "            if content == \"1\":\n",
        "                scores.append(1)\n",
        "            elif content == \"2\":\n",
        "                scores.append(2)\n",
        "            else:\n",
        "                print(f\"Invalid response: {content}\")\n",
        "                scores.append(0)  # Default score for invalid responses\n",
        "        except (KeyError, Exception) as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            scores.append(0)  # Default score for errors\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rKct4c5QqTsp"
      },
      "outputs": [],
      "source": [
        "def main_evaluation(novice_prompts, expert1_prompts, expert2_prompts):\n",
        "    scores = evaluate_with_openai(novice_prompts, expert1_prompts, expert2_prompts)\n",
        "\n",
        "    # Calculate win rates\n",
        "    expert1_wins = scores.count(1)\n",
        "    expert2_wins = scores.count(2)\n",
        "    total = len(scores)\n",
        "\n",
        "    print(f\"Expert Version 1 Win Rate: {expert1_wins / total:.2%}\")\n",
        "    print(f\"Expert Version 2 Win Rate: {expert2_wins / total:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKOlibfOqX_-",
        "outputId": "b221297f-d2d6-4e6f-8be3-42948ee8911a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: I would choose 'Expert\n",
            "Invalid response: I would choose 'Expert\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 1\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 1\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 1\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 1\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: 2\n",
            "Response: I would choose rewrite\n",
            "Invalid response: I would choose rewrite\n",
            "Response: 2\n",
            "Expert Version 1 Win Rate: 4.00%\n",
            "Expert Version 2 Win Rate: 94.00%\n"
          ]
        }
      ],
      "source": [
        "main_evaluation(\n",
        "    df_novice_test.head(100).tolist(),\n",
        "    df_expert1_test.head(100).tolist(),\n",
        "    df_expert2_test.head(100).tolist()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
